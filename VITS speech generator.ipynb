{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "938FhDaCtNPQ",
    "outputId": "49dc612f-77fe-4daf-f7e6-33dabde685fe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q espnet==0.10.6 pyopenjtalk==0.2 pypinyin==0.44.0 parallel_wavegan==0.5.4 gdown==4.4.0 espnet_model_zoo\n",
    "!pip install typeguard==2.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TrbjHksEtYwq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torchaudio\n",
    "from torchaudio.datasets.librispeech import LIBRISPEECH\n",
    "import torchaudio.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "HsCT9DoptbXX",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5.95G/5.95G [07:02<00:00, 15.1MB/s]\n"
     ]
    }
   ],
   "source": [
    "PATH=\"/home/ubuntu/test/Synthetic ASR- IDL Project/\"\n",
    "COMPLETE_DATASET_PATH = PATH + \"/librispeech\"\n",
    "\n",
    "if not os.path.exists(COMPLETE_DATASET_PATH):\n",
    "  os.mkdir(COMPLETE_DATASET_PATH)\n",
    "\n",
    "COMPLETE_DATASET = torchaudio.datasets.LIBRISPEECH(COMPLETE_DATASET_PATH, url='train-clean-100', download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fxlYD8VethfN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title English multi-speaker pretrained model { run: \"auto\" }\n",
    "lang = 'English'\n",
    "tag = 'kan-bayashi/vctk_multi_spk_vits' #@param [\"kan-bayashi/vctk_gst_tacotron2\", \"kan-bayashi/vctk_gst_transformer\", \"kan-bayashi/vctk_xvector_tacotron2\", \"kan-bayashi/vctk_xvector_transformer\", \"kan-bayashi/vctk_xvector_conformer_fastspeech2\", \"kan-bayashi/vctk_gst+xvector_tacotron2\", \"kan-bayashi/vctk_gst+xvector_transformer\", \"kan-bayashi/vctk_gst+xvector_conformer_fastspeech2\", \"kan-bayashi/vctk_multi_spk_vits\", \"kan-bayashi/vctk_full_band_multi_spk_vits\", \"kan-bayashi/libritts_xvector_transformer\", \"kan-bayashi/libritts_xvector_conformer_fastspeech2\", \"kan-bayashi/libritts_gst+xvector_transformer\", \"kan-bayashi/libritts_gst+xvector_conformer_fastspeech2\", \"kan-bayashi/libritts_xvector_vits\"] {type:\"string\"}\n",
    "vocoder_tag = \"none\" #@param [\"none\", \"parallel_wavegan/vctk_parallel_wavegan.v1.long\", \"parallel_wavegan/vctk_multi_band_melgan.v2\", \"parallel_wavegan/vctk_style_melgan.v1\", \"parallel_wavegan/vctk_hifigan.v1\", \"parallel_wavegan/libritts_parallel_wavegan.v1.long\", \"parallel_wavegan/libritts_multi_band_melgan.v2\", \"parallel_wavegan/libritts_hifigan.v1\", \"parallel_wavegan/libritts_style_melgan.v1\"] {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from espnet2.bin.tts_inference import Text2Speech\n",
    "from espnet2.utils.types import str_or_none\n",
    "\n",
    "text2speech = Text2Speech.from_pretrained(\n",
    "    model_tag=str_or_none(tag),\n",
    "    vocoder_tag=str_or_none(vocoder_tag),\n",
    "    device=\"cuda\",\n",
    "    # device=\"cpu\",\n",
    "    speed_control_alpha=0.8,\n",
    "    noise_scale=0.2,\n",
    "    noise_scale_dur=0.2,\n",
    "    length_scale= \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "o7z5kFdNt1Bm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import kaldiio\n",
    "\n",
    "# Get model directory path\n",
    "from espnet_model_zoo.downloader import ModelDownloader\n",
    "d = ModelDownloader()\n",
    "model_dir = os.path.dirname(d.download_and_unpack(tag)[\"train_config\"])\n",
    "\n",
    "def get_random_speaker():\n",
    "  sids = None\n",
    "  if text2speech.use_sids:\n",
    "      spk2sid = glob.glob(f\"{model_dir}/../../dump/**/spk2sid\", recursive=True)[0]\n",
    "      with open(spk2sid) as f:\n",
    "          lines = [line.strip() for line in f.readlines()]\n",
    "      sid2spk = {int(line.split()[1]): line.split()[0] for line in lines}\n",
    "      \n",
    "      # randomly select speaker\n",
    "      sids = np.array(np.random.randint(1, len(sid2spk)))\n",
    "      spk = sid2spk[int(sids)]\n",
    "      return sids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiru2AKXuDJK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = COMPLETE_DATASET\n",
    "\n",
    "tts_model = text2speech\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for i, (waveform, sample_rate, utterance, speaker_id, chapter_id, utterance_id) in enumerate(dataset):\n",
    "\n",
    "    if i % 500 == 0:\n",
    "        print(i)\n",
    "    transcript_str = dataset[i][2]\n",
    "\n",
    "    wav = text2speech(transcript_str, sids=get_random_speaker())[\"wav\"]\n",
    "    wav = wav.squeeze().cpu().numpy()\n",
    "    wav = np.expand_dims(wav, axis=0)\n",
    "\n",
    "    filename = f\"sample_{i}\"\n",
    "    torchaudio.save('/home/ubuntu/test/Synthetic ASR- IDL Project/new/Multi-Speaker/'+filename + '.wav',torch.from_numpy(wav) , sample_rate=16000)\n",
    "    with open('/home/ubuntu/test/Synthetic ASR- IDL Project/new/multi-speaker-trans/sample_'+ str(i) + '.txt', 'w') as f:\n",
    "        f.write(transcript_str)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_idl)",
   "language": "python",
   "name": "conda_idl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
